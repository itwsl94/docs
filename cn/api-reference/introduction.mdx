---
title: '推理接口文档'
description: 'Example section for showcasing API endpoints'
---

## 接口功能
提供文本/流式推理处理功能。

## 接口格式
操作类型：POST

**URL**：https://api.siliconstorm.ai/v1/chat/completions
```bash
curl --location --request POST 'https://api.siliconstorm.ai/v1/chat/completions'
--header 'Authorization: Bearer {ApiKey}'
--header 'User-Agent: Apifox/1.0.0 (https://apifox.com)'
--header 'Content-Type: application/json'
--header 'Accept: */*'
--header 'Host: api.siliconstorm.ai'
--header 'Connection: keep-alive'
--data-raw '{
  "model": "DeepSeek-R1",
  "messages": [
    {
      "content": "写一段helloword并解释代码",
      "role": "user"
    }
  ],
  "stream":true
}'
```

## 请求参数

<table cellpadding="4" cellspacing="0" frame="border" border="1" rules="all" data-header="7">
    <thead align="left">
    <tr>
        <th align="left" colspan="4" valign="top"><p>参数</p></th>
        <th align="left" valign="top"><p>是否必选</p></th>
        <th align="left" valign="top"><p>说明</p> </th>
        <th align="left" valign="top"><p>取值要求</p></th>
    </tr>
    </thead>
    <tbody><tr>
        <td colspan="4"><p>model</p></td>
        <td><p>必选</p></td>
        <td><p>模型名</p></td>
        <td><p>与<span>MindIE Server</span>配置文件中modelName的取值保持一致。</p></td>
    </tr>
    <tr>
        <td colspan="4"><p>messages</p></td>
        <td><p>必选</p></td>
        <td><p>推理请求消息结构。</p></td>
        <td><p>list类型，0KB&lt;messages内容包含的字符数&lt;=4MB，支持中英文。tokenizer之后的token数量小于或等于maxInputTokenLen、maxSeqLen-1、max_position_embeddings和1MB之间的最小值。其中，max_position_embeddings从权重文件config.json中获取，其他相关参数从配置文件中获取。</p></td>
    </tr>
    <tr>
        <td rowspan="12"><p>-</p></td>
        <td colspan="3"><p>role</p></td>
        <td><p>必选</p></td>
        <td><p>推理请求消息角色。</p></td>
        <td><p>字符串类型，可取角色有：</p>
            <ul><li>system：系统角色</li><li>user：用户角色</li><li>assistant：助手角色</li><li>tool：工具角色</li></ul></td>
    </tr>
    <tr>
        <td colspan="3"><p>content</p></td>
        <td><p>必选</p></td>
        <td><p>推理请求内容。单模态文本模型为string类型，多模态模型为list类型。</p></td>
        <td><ul><li>string：<ul><li>当role为assistant，且tool_calls非空时，content可以不传，其余角色非空。</li><li>其余情况content非空。</li></ul>
        </li><li>list：形如多模态模型inputs参数的示例格式即可。</li></ul></td>
    </tr>
    <tr>
        <td rowspan="5"><p>-</p></td>
        <td colspan="2"><p>type</p></td>
        <td><p>可选</p></td>
        <td><p>推理请求内容类型。</p></td>
        <td><ul><li>text：文本</li><li>image_url：图片</li><li>video_url：视频</li><li>audio_url：音频</li></ul>
            <p>单个请求中image_url、video_url、audio_url数量总和&lt;=20个。</p></td>
    </tr>
    <tr>
        <td colspan="2"><p>text</p></td>
        <td><p>可选</p></td>
        <td><p>推理请求内容为文本。</p></td>
        <td><p>非空，支持中英文。</p></td>
    </tr>
    <tr>
        <td colspan="2"><p>image_url</p></td>
        <td><p>可选</p></td>
        <td><p>推理请求内容为图片。</p></td>
        <td><p>支持服务器本地路径的图片传入，图片类型支持jpg、png、jpeg和base64编码的jpg图片，支持URL图片传入，支持HTTP和HTTPS协议。当前支持传入的图片最大为20MB。</p></td>
    </tr>
    <tr>
        <td colspan="2"><p>video_url</p></td>
        <td><p>可选</p></td>
        <td><p>推理请求内容为视频。</p></td>
        <td><p>支持服务器本地路径的视频传入，视频类型支持MP4、AVI、WMV，支持URL视频传入，支持HTTP和HTTPS协议。当前支持传入的视频最大为512MB。</p></td>
    </tr>
    <tr>
        <td colspan="2"><p>audio_url</p></td>
        <td><p>可选</p></td>
        <td><p>推理请求内容为音频。</p></td>
        <td><p>支持服务器本地路径的音频传入，音频类型支持MP3、WAV、FLAC，支持URL音频传入，支持HTTP和HTTPS协议。当前支持传入的音频最大为20MB。</p></td>
    </tr>
    <tr>
        <td colspan="3"><p>tool_calls</p></td>
        <td><p>可选</p></td>
        <td><p>模型生成的工具调用。</p></td>
        <td><p>类型为List[dict]，当role为assistant时，表示模型对工具的调用。</p></td>
    </tr>
    <tr>
        <td rowspan="3"><p>-</p></td>
        <td colspan="2"><p>function</p></td>
        <td><p>必选</p></td>
        <td><p>表示模型调用的工具。</p></td>
        <td><p>dict类型。</p>
            <ul><li>arguments，必选，使用JSON格式的字符串，表示调用函数的参数。</li><li>name，必选，字符串，调用的函数名。</li></ul></td>
    </tr>
    <tr>
        <td colspan="2"><p>id</p></td>
        <td><p>必选</p></td>
        <td><p>表示模型某次工具调用的ID。</p></td>
        <td><p>字符串。</p></td>
    </tr>
    <tr>
        <td colspan="2"><p>type</p></td>
        <td><p>必选</p></td>
        <td><p>调用的工具类型。</p></td>
        <td><p>字符串，仅支持"function"。</p></td>
    </tr>
    <tr>
        <td colspan="3"><p>tool_call_id</p></td>
        <td><p>当role为tool时必选，否则可选</p></td>
        <td><p>关联模型某次调用工具时的ID。</p></td>
        <td><p>字符串。</p></td>
    </tr>
    <tr>
        <td colspan="4"><p>stream</p></td>
        <td><p>可选</p></td>
        <td><p>指定返回结果是文本推理还是流式推理。</p></td>
        <td><p>bool类型参数，默认值false。</p>
            <ul><li>true：流式推理。</li><li>false：文本推理。</li></ul></td>
    </tr>
    <tr>
        <td colspan="4"><p>presence_penalty</p></td>
        <td><p>可选</p></td>
        <td><p>存在惩罚介于-2.0和2.0之间，它影响模型如何根据到目前为止是否出现在文本中来惩罚新token。正值将通过惩罚已经使用的词，增加模型谈论新主题的可能性。</p></td>
        <td><p>float类型，取值范围[-2.0, 2.0]，默认值0.0。</p></td>
    </tr>
    <tr>
        <td colspan="4"><p>frequency_penalty</p></td>
        <td><p>可选</p></td>
        <td><p>频率惩罚介于-2.0和2.0之间，它影响模型如何根据文本中词汇的现有频率惩罚新词汇。正值将通过惩罚已经频繁使用的词来降低模型一行中重复用词的可能性。</p></td>
        <td><p>float类型，取值范围[-2.0, 2.0]，默认值0.0。</p></td>
    </tr>
    <tr>
        <td colspan="4"><p>repetition_penalty</p></td>
        <td><p>可选</p></td>
        <td><p>重复惩罚是一种技术，用于减少在文本生成过程中出现重复片段的概率。它对之前已经生成的文本进行惩罚，使得模型更倾向于选择新的、不重复的内容。</p></td>
        <td><p>float类型，取值范围(0.0, 2.0]，默认值1.0。</p></td>
    </tr>
    <tr>
        <td colspan="4"><p>temperature</p></td>
        <td><p>可选</p></td>
        <td><p>控制生成的随机性，较高的值会产生更多样化的输出。</p></td>
        <td><p>float类型，取值范围[0.0, 2.0]，默认值1.0。</p>
            <p>取值越大，结果的随机性越大。推荐使用大于或等于0.001的值，小于0.001可能会导致文本质量不佳。</p></td>
    </tr>
    <tr>
        <td colspan="4"><p>top_p</p></td>
        <td><p>可选</p></td>
        <td><p>控制模型生成过程中考虑的词汇范围，使用累计概率选择候选词，直到累计概率超过给定的阈值。该参数也可以控制生成结果的多样性，它基于累积概率选择候选词，直到累计概率超过给定的阈值为止。</p></td>
        <td><p>float类型，取值范围(0.0, 1.0]，默认值1.0。</p></td>
    </tr>
    <tr>
        <td colspan="4"><p>top_k</p></td>
        <td><p>可选</p></td>
        <td><p>控制模型生成过程中考虑的词汇范围，只从概率最高的k个候选词中选择。</p></td>
        <td><p>int32类型，取值范围[0, 2147483647]，字段未设置时，默认值由后端模型确定，详情请参见<a href="mindie_service0062.html" data-outer="inner" data-href="mindie_service0062.html" data-doc="true" target="_blank" data-multiple-screen="true">说明</a>。取值大于或等于vocabSize时，默认值为vocabSize。</p>
            <p>vocabSize是从modelWeightPath路径下的config.json文件中读取的vocab_size或者padded_vocab_size的值。建议用户在config.json文件中添加vocab_size或者padded_vocab_size参数，否则可能导致推理失败。</p></td>
    </tr>
    <tr>
        <td colspan="4"><p>seed</p></td>
        <td><p>可选</p></td>
        <td><p>用于指定推理过程的随机种子，相同的seed值可以确保推理结果的可重现性，不同的seed值会提升推理结果的随机性。</p></td>
        <td><p>uint_64类型，取值范围[0, 18446744073709551615]，不传递该参数，系统会产生一个随机seed值。</p>
            <p>当seed取到临近最大值时，会有WARNING，但并不会影响使用。若想去掉WARNING，可以减小seed取值。</p></td>
    </tr>
    <tr>
        <td colspan="4"><p>stop</p></td>
        <td><p>可选</p></td>
        <td><p>停止推理的文本。输出结果默认不包含停止词列表文本。</p></td>
        <td>
            <p>List[string]类型或者string类型，默认值null。</p>
            <ul>
                <li>List[string]类型列表元素不超过1024个，每个元素的长度为1~1024，列表元素总长度不超过32768（256*128）。列表为空时相当于null。</li>
                <li>string类型长度范围为1Some ~strikethrough~ text1024。</li>
            </ul>
            <p>PD分离场景暂不支持该参数。</p>
        </td>
    </tr>
    <tr>
        <td colspan="4"><p>stop_token_ids</p></td>
        <td><p>可选</p></td>
        <td><p>停止推理的token id列表。输出结果默认不包含停止推理列表中的token id。</p></td>
        <td><p>List[int32]类型，超出int32的元素将会被忽略，默认值null。</p></td>
    </tr>
    <tr>
        <td colspan="4"><p>include_stop_str_in_output</p></td>
        <td><p>可选</p></td>
        <td><p>决定是否在生成的推理文本中包含停止字符串。</p></td>
        <td><p>bool类型，默认值false。</p>
            <ul><li>true：包含停止字符串。</li><li>false：不包含停止字符串。</li></ul>
            <p>不传入stop或stop_token_ids时，此字段会被忽略。</p>
            <p>PD分离场景暂不支持此参数。</p></td>
    </tr>
    <tr>
        <td colspan="4"><p>skip_special_tokens</p></td>
        <td><p>可选</p></td>
        <td><p>指定在推理生成的文本中是否跳过特殊tokens。</p></td>
        <td><p>bool类型，默认值true。</p>
            <ul><li>true：跳过特殊tokens。</li><li>false：保留特殊tokens。</li></ul></td>
    </tr>
    <tr>
        <td colspan="4"><p>ignore_eos</p></td>
        <td><p>可选</p></td>
        <td><p>指定在推理文本生成过程中是否忽略eos_token结束符。</p></td>
        <td><p>bool类型，默认值false。</p>
            <ul><li>true：忽略eos_token结束符。</li><li>false：不忽略eos_token结束符。</li></ul></td>
    </tr>
    <tr>
        <td colspan="4"><p>max_tokens</p></td>
        <td><p>可选</p></td>
        <td><p>允许推理生成的最大token个数。实际产生的token数量同时受到配置文件maxIterTimes参数影响，推理token个数小于或等于min(maxIterTimes, max_tokens)。</p></td>
        <td><p>int类型，取值范围(0，2147483647]，默认值maxIterTimes。</p></td>
    </tr>
    <tr>
        <td colspan="4"><p>tools</p></td>
        <td><p>可选</p></td>
        <td><p>可能会使用的工具列表。</p></td>
        <td><p>List[dict]类型。</p></td>
    </tr>
    <tr>
        <td rowspan="10"><p>-</p></td>
        <td colspan="3"><p>type</p></td>
        <td><p>必选</p></td>
        <td><p>说明工具类型。</p></td>
        <td><p>仅支持字符串"function"。</p></td>
    </tr>
    <tr>
        <td colspan="3"><p>function</p></td>
        <td><p>必选</p></td>
        <td><p>函数描述。</p></td>
        <td><p>dict类型。</p></td>
    </tr>
    <tr>
        <td rowspan="8"><p>-</p></td>
        <td colspan="2"><p>name</p></td>
        <td><p>必选</p></td>
        <td><p>函数名称。</p></td>
        <td><p>字符串。</p></td>
    </tr>
    <tr>
        <td colspan="2"><p>strict</p></td>
        <td><p>可选</p></td>
        <td><p>表示生成tool calls是否严格遵循schema格式。</p></td>
        <td><p>bool类型，默认false。</p></td>
    </tr>
    <tr>
        <td colspan="2"><p>description</p></td>
        <td><p>可选</p></td>
        <td><p>描述函数功能和使用。</p></td>
        <td><p>字符串。</p></td>
    </tr>
    <tr>
        <td colspan="2"><p>parameters</p></td>
        <td><p>可选</p></td>
        <td><p>表示函数接受的参数。</p></td>
        <td><p>JSON schema格式。</p></td>
    </tr>
    <tr>
        <td rowspan="4"><p>-</p></td>
        <td><p>type</p></td>
        <td><p>必选</p></td>
        <td><p>表示函数参数属性的类型。</p></td>
        <td><p>字符串，仅支持object。</p></td>
    </tr>
    <tr>
        <td><p>properties</p></td>
        <td><p>必选</p></td>
        <td><p>函数参数的属性。每一个key表示一个参数名，由用户自定义。value为dict类型，表示参数描述，包含type和description两个参数。</p></td>
        <td><p>dict类型。</p></td>
    </tr>
    <tr>
        <td><p>required</p></td>
        <td><p>必选</p></td>
        <td><p>表示函数必填参数列表。</p></td>
        <td><p>List[string]类型。</p></td>
    </tr>
    <tr>
        <td><p>additionalProperties</p></td>
        <td><p>可选</p></td>
        <td><p>是否允许使用未提及的额外参数。</p></td>
        <td><p>bool类型，默认值false。</p>
            <ul><li>true：允许使用未提及的额外参数。</li><li>false：不允许使用未提及的额外参数。</li></ul></td>
    </tr>
    <tr>
        <td colspan="4"><p>tool_choice</p></td>
        <td><p>可选</p></td>
        <td><p>控制模型调用工具。</p></td>
        <td><p>string类型或者dict类型，可以为null，默认值"auto"。</p>
            <ul><li>"none"：表示模型不会调用任何工具，而是生成一条消息。</li><li>"auto"：表示模型可以生成消息或调用一个或多个工具。</li><li>"required"：表示模型必须调用一个或多个工具。</li></ul>
            <p>通过{"{type: 'function', function: {name: 'my_function'}}"}指定特定的工具，将强制模型调用该工具。</p></td>
    </tr>
    </tbody>
</table>


## 使用样例

### 单轮对话：

#### 单模态模型：

```json
{
    "model": "DeepSeek-R1",
    "messages": [{
        "role": "user",
        "content": "You are a helpful assistant."
    }],
    "stream": false,
    "presence_penalty": 1.03,
    "frequency_penalty": 1.0,
    "repetition_penalty": 1.0,
    "temperature": 0.5,
    "top_p": 0.95,
    "top_k": 0,
    "seed": null,
    "stop": ["stop1", "stop2"],
    "stop_token_ids": [2, 13],
    "include_stop_str_in_output": false,
    "skip_special_tokens": true,
    "ignore_eos": false,
    "max_tokens": 20
}
```

#### 多模态模型：
说明: "image_url"参数的取值请根据实际情况进行修改。

```json
{
    "model": "DeepSeek-R1",
    "messages": [{
        "role": "user",
        "content": [
           {"type": "text", "text": "My name is Olivier and I"},
           {"type": "image_url", "image_url": "/xxxx/test.png"}
        ]
    }],
    "stream": false,
    "presence_penalty": 1.03,
    "frequency_penalty": 1.0,
    "repetition_penalty": 1.0,
    "temperature": 0.5,
    "top_p": 0.95,
    "top_k": 0,
    "seed": null,
    "stop": ["stop1", "stop2"],
    "stop_token_ids": [2, 13],
    "include_stop_str_in_output": false,
    "skip_special_tokens": true,
    "ignore_eos": false,
    "max_tokens": 20
}
```
### 多轮对话

##### 请求样例1：
```json
{
    "model": "DeepSeek-R1",
    "messages": [{
        "role": "system",
        "content": "You are a helpful customer support assistant. Use the supplied tools to assist the user."
        },
        {
        "role": "user",
        "content": "Hi, can you tell me the delivery date for my order? my order id is 12345."
        }
    ],
    "stream": false,
    "presence_penalty": 1.03,
    "frequency_penalty": 1.0,
    "repetition_penalty": 1.0,
    "temperature": 0.5,
    "top_p": 0.95,
    "top_k": 0,
    "seed": null,
    "stop": ["stop1", "stop2"],
    "stop_token_ids": [2],
    "ignore_eos": false,
    "max_tokens": 1024,
    "tools": [
        {
            "type": "function",
            "function": {
                "name": "get_delivery_date",
                "strict": true,
                "description": "Get the delivery date for a customer's order. Call this whenever you need to know the delivery date, for example when a customer asks 'Where is my package'",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "order_id": {
                            "type": "string",
                            "description": "The customer's order ID."
                        }
                    },
                    "required": [
                        "order_id"
                    ],
                    "additionalProperties": false
                }
            }
        }
    ],
   "tool_choice": "auto"
}
```

#### 请求样例2：
```json
{
    "model": "DeepSeek-R1",
    "messages": [
        {
            "role": "system",
            "content": "You are a helpful customer support assistant. Use the supplied tools to assist the user."
        },
        {
            "role": "user",
            "content": "Hi, can you tell me the delivery date for my order? my order id is 12345."
        },
        {
            "role": "assistant",
            "tool_calls": [
                {
                    "function": {
                        "arguments": "{\"order_id\": \"12345\"}",
                        "name": "get_delivery_date"
                    },
                    "id": "tool_call_8p2Nk",
                    "type": "function"
                }
            ]
        },
        {
            "role": "tool",
            "content": "the delivery date is 2024.09.10.",
            "tool_call_id": "tool_call_8p2Nk"
        }
    ],
    "stream": false,
    "repetition_penalty": 1.1,
    "temperature": 0.9,
    "top_p": 1,
    "max_tokens": 1024,
    "tools": [
        {
            "type": "function",
            "function": {
                "name": "get_delivery_date",
                "strict": true,
                "description": "Get the delivery date for a customer's order. Call this whenever you need to know the delivery date, for example when a customer asks 'Where is my package'",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "order_id": {
                            "type": "string",
                            "description": "The customer's order ID."
                        }
                    },
                    "required": [
                        "order_id"
                    ],
                    "additionalProperties": false
                }
            }
        }
    ],
    "tool_choice": "auto"
}
```

## 响应样例：
文本推理（“stream”=false）：

### 单轮对话：
```json
{
    "id": "chatcmpl-123",
    "object": "chat.completion",
    "created": 1677652288,
    "model": "DeepSeek-R1",
    "choices": [
        {
            "index": 0,
            "message": {
                "role": "assistant",
                "content": "\n\nHello there, how may I assist you today?"
            },
            "finish_reason": "stop"
        }
    ],
    "usage": {
        "prompt_tokens": 9,
        "completion_tokens": 12,
        "total_tokens": 21
    },
    "prefill_time": 200,
    "decode_time_arr": [56, 28, 28]
}
```
### 多轮对话：

#### 响应样例1：
```json
{
    "id": "chatcmpl-123",
    "object": "chat.completion",
    "created": 1677652288,
    "model": "DeepSeek-R1",
    "choices": [
        {
            "index": 0,
            "message": {
                "role": "assistant",
                "content": "",
                "tool_calls": [
                    {
                        "function": {
                            "arguments": "{\"order_id\": \"12345\"}",
                            "name": "get_delivery_date"
                        },
                        "id": "call_JwmTNF3O",
                        "type": "function"
                    }
                ]
            },
            "finish_reason": "tool_calls"
        }
    ],
    "usage": {
        "prompt_tokens": 226,
        "completion_tokens": 122,
        "total_tokens": 348
    },
    "prefill_time": 200,
    "decode_time_arr": [56, 28, 28]
}
```
#### 响应样例2：
```json
{
    "id": "endpoint_common_25",
    "object": "chat.completion",
    "created": 1728959154,
    "model": "DeepSeek-R1",
    "choices": [
        {
            "index": 0,
            "message": {
                "role": "assistant",
                "content": "\n Your order with ID 12345 is scheduled for delivery on September 10th, 2024.",
                "tool_calls": null
            },
            "finish_reason": "stop"
        }
    ],
    "usage": {
        "prompt_tokens": 265,
        "completion_tokens": 30,
        "total_tokens": 295
    },
    "prefill_time": 200,
    "decode_time_arr": [56, 28, 28]
}
```

### 流式推理：

#### 流式推理1（“stream”=true，使用sse格式返回）：
```json

data: {"id":"endpoint_common_8","object":"chat.completion.chunk","created":1729614610,"model":"DeepSeek-R1","choices":[{"index":0,"delta":{"role":"assistant","content":"\t"},"finish_reason":null}]}

data: {"id":"endpoint_common_8","object":"chat.completion.chunk","created":1729614610,"model":"DeepSeek-R1","choices":[{"index":0,"delta":{"role":"assistant","content":""},"finish_reason":null}]}

data: {"id":"endpoint_common_8","object":"chat.completion.chunk","created":1729614610,"model":"DeepSeek-R1","choices":[{"index":0,"delta":{"role":"assistant","content":""},"finish_reason":null}]}

data: {"id":"endpoint_common_8","object":"chat.completion.chunk","created":1729614610,"model":"DeepSeek-R1","choices":[{"index":0,"delta":{"role":"assistant","content":""},"finish_reason":null}]}

data: {"id":"endpoint_common_8","object":"chat.completion.chunk","created":1729614610,"model":"DeepSeek-R1","choices":[{"index":0,"delta":{"role":"assistant","content":""},"finish_reason":null}]}

data: {"id":"endpoint_common_8","object":"chat.completion.chunk","created":1729614610,"model":"DeepSeek-R1","choices":[{"index":0,"delta":{"role":"assistant","content":"\t"},"finish_reason":null}]}

data: {"id":"endpoint_common_8","object":"chat.completion.chunk","created":1729614610,"model":"DeepSeek-R1","choices":[{"index":0,"delta":{"role":"assistant","content":""},"finish_reason":null}]}

data: {"id":"endpoint_common_8","object":"chat.completion.chunk","created":1729614610,"model":"DeepSeek-R1","choices":[{"index":0,"delta":{"role":"assistant","content":""},"finish_reason":null}]}

data: {"id":"endpoint_common_8","object":"chat.completion.chunk","created":1729614610,"model":"DeepSeek-R1","choices":[{"index":0,"delta":{"role":"assistant","content":""},"finish_reason":null}]}

data: {"id":"endpoint_common_8","object":"chat.completion.chunk","created":1729614610,"model":"DeepSeek-R1","choices":[{"index":0,"delta":{"role":"assistant","content":""},"finish_reason":null}]}

data: {"id":"endpoint_common_8","object":"chat.completion.chunk","created":1729614610,"model":"DeepSeek-R1","choices":[{"index":0,"delta":{"role":"assistant","content":""},"finish_reason":null}]}

data: {"id":"endpoint_common_8","object":"chat.completion.chunk","created":1729614610,"model":"DeepSeek-R1","choices":[{"index":0,"delta":{"role":"assistant","content":""},"finish_reason":null}]}

data: {"id":"endpoint_common_8","object":"chat.completion.chunk","created":1729614610,"model":"DeepSeek-R1","choices":[{"index":0,"delta":{"role":"assistant","content":""},"finish_reason":null}]}

data: {"id":"endpoint_common_8","object":"chat.completion.chunk","created":1729614610,"model":"DeepSeek-R1","choices":[{"index":0,"delta":{"role":"assistant","content":""},"finish_reason":null}]}

data: {"id":"endpoint_common_8","object":"chat.completion.chunk","created":1729614610,"model":"DeepSeek-R1","choices":[{"index":0,"delta":{"role":"assistant","content":""},"finish_reason":null}]}

data: {"id":"endpoint_common_8","object":"chat.completion.chunk","created":1729614610,"model":"DeepSeek-R1","choices":[{"index":0,"delta":{"role":"assistant","content":""},"finish_reason":null}]}

data: {"id":"endpoint_common_8","object":"chat.completion.chunk","created":1729614610,"model":"DeepSeek-R1","usage":{"prompt_tokens":54,"completion_tokens":17,"total_tokens":71},"choices":[{"index":0,"delta":{"role":"assistant","content":""},"finish_reason":"stop"}]}

data: [DONE]
```
#### 流式推理2（“stream”=true，配置项“fullTextEnabled”=true，使用sse格式返回）：
```json
data: {"id":"endpoint_common_11","object":"chat.completion.chunk","created":1730184192,"model":"DeepSeek-R1","choices":[{"index":0,"delta":{"role":"assistant","content":"Hello"},"finish_reason":null}]}

data: {"id":"endpoint_common_11","object":"chat.completion.chunk","created":1730184192,"model":"DeepSeek-R1","choices":[{"index":0,"delta":{"role":"assistant","content":"Hello!"},"finish_reason":null}]}

data: {"id":"endpoint_common_11","object":"chat.completion.chunk","created":1730184192,"model":"DeepSeek-R1","choices":[{"index":0,"delta":{"role":"assistant","content":"Hello! How"},"finish_reason":null}]}

data: {"id":"endpoint_common_11","object":"chat.completion.chunk","created":1730184192,"model":"DeepSeek-R1","choices":[{"index":0,"delta":{"role":"assistant","content":"Hello! How can"},"finish_reason":null}]}

data: {"id":"endpoint_common_11","object":"chat.completion.chunk","created":1730184192,"model":"DeepSeek-R1","choices":[{"index":0,"delta":{"role":"assistant","content":"Hello! How can I"},"finish_reason":null}]}

data: {"id":"endpoint_common_11","object":"chat.completion.chunk","created":1730184192,"model":"DeepSeek-R1","choices":[{"index":0,"delta":{"role":"assistant","content":"Hello! How can I assist"},"finish_reason":null}]}

data: {"id":"endpoint_common_11","object":"chat.completion.chunk","created":1730184192,"model":"DeepSeek-R1","choices":[{"index":0,"delta":{"role":"assistant","content":"Hello! How can I assist you"},"finish_reason":null}]}

data: {"id":"endpoint_common_11","object":"chat.completion.chunk","created":1730184192,"model":"DeepSeek-R1","choices":[{"index":0,"delta":{"role":"assistant","content":"Hello! How can I assist you today"},"finish_reason":null}]}

data: {"id":"endpoint_common_11","object":"chat.completion.chunk","created":1730184192,"model":"DeepSeek-R1","choices":[{"index":0,"delta":{"role":"assistant","content":"Hello! How can I assist you today?"},"finish_reason":null}]}

data: {"id":"endpoint_common_11","object":"chat.completion.chunk","created":1730184192,"model":"DeepSeek-R1","full_text":"Hello! How can I assist you today?","usage":{"prompt_tokens":31,"completion_tokens":10,"total_tokens":41},"choices":[{"index":0,"delta":{"role":"assistant","content":"Hello! How can I assist you today?"},"finish_reason":"length"}]}

data: [DONE]
```

## 输出说明
### 表1 文本推理结果说明

<table cellpadding="4" cellspacing="0" frame="border" border="1" rules="all" data-header="7">
    <thead align="left">
    <tr>
        <th align="left" colspan="5"><p>参数名</p></th>
        <th align="left"><p>类型</p></th>
        <th align="left"><p>说明</p></th>
    </tr>
    </thead>
    <tbody>
    <tr>
        <td colspan="5"><p>id</p></td>
        <td><p>string</p></td>
        <td><p>请求ID。</p></td>
    </tr>
    <tr>
        <td colspan="5"><p>object</p></td>
        <td><p>string</p></td>
        <td><p>返回结果类型目前都返回"chat.completion"。</p></td>
    </tr>
    <tr>
        <td colspan="5"><p>created</p></td>
        <td><p>integer</p></td>
        <td><p>推理请求时间戳，精确到秒。</p></td>
    </tr>
    <tr>
        <td colspan="5"><p>model</p></td>
        <td><p>string</p></td>
        <td><p>使用的推理模型。</p></td>
    </tr>
    <tr>
        <td colspan="5"><p>choices</p></td>
        <td><p>list</p></td>
        <td><p>推理结果列表。</p></td>
    </tr>
    <tr>
        <td rowspan="11"><p>-</p></td>
        <td colspan="4"><p>index</p></td>
        <td><p>integer</p></td>
        <td><p>choices消息index，当前只能为0。</p></td>
    </tr>
    <tr>
        <td colspan="4"><p>message</p></td>
        <td><p>object</p></td>
        <td><p>推理消息。</p></td>
    </tr>
    <tr>
        <td rowspan="8"><p>-</p></td>
        <td colspan="3"><p>role</p></td>
        <td><p>string</p></td>
        <td><p>角色，目前都返回"assistant"。</p></td>
    </tr>
    <tr>
        <td colspan="3"><p>content</p></td>
        <td><p>string</p></td>
        <td><p>推理文本结果。</p></td>
    </tr>
    <tr>
        <td colspan="3"><p>tool_calls</p></td>
        <td><p>list</p></td>
        <td><p>模型工具调用输出。</p></td>
    </tr>
    <tr>
        <td rowspan="5"><p>-</p></td>
        <td colspan="2"><p>function</p></td>
        <td><p>dict</p></td>
        <td><p>函数调用说明。</p></td>
    </tr>
    <tr>
        <td rowspan="2"><p>-</p></td>
        <td><p>arguments</p></td>
        <td><p>string</p></td>
        <td><p>调用函数的参数，JSON格式的字符串。</p></td>
    </tr>
    <tr>
        <td><p>name</p></td>
        <td><p>string</p></td>
        <td><p>调用的函数名。</p></td>
    </tr>
    <tr>
        <td colspan="2"><p>id</p></td>
        <td><p>string</p></td>
        <td><p>模型调用工具的ID。</p></td>
    </tr>
    <tr>
        <td colspan="2"><p>type</p></td>
        <td><p>string</p></td>
        <td><p>工具的类型，目前仅支持function。</p></td>
    </tr>
    <tr>
        <td colspan="4"><p>finish_reason</p></td>
        <td><p>string</p></td>
        <td>
            <p>结束原因。</p>
            <ul>
                <li>
                    stop：
                    <ul>
                        <li>请求被CANCEL或STOP，用户不感知，丢弃响应。</li>
                        <li>请求执行中出错，响应输出为空，err_msg非空。</li>
                        <li>请求输入校验异常，响应输出为空，err_msg非空。</li>
                        <li>请求遇eos结束符正常结束。</li>
                    </ul>
                </li>
                <li>
                    length：
                    <ul>
                        <li>请求因达到最大序列长度而结束，响应为最后一轮迭代输出。</li>
                        <li>请求因达到最大输出长度（包括请求和模型粒度）而结束，响应为最后一轮迭代输出。</li>
                    </ul>
                </li>
                <li>tool_calls：表示模型调用了工具。</li>
            </ul>
        </td>
    </tr>
    <tr>
        <td colspan="5"><p>usage</p></td>
        <td><p>object</p></td>
        <td><p>推理结果统计数据。</p></td>
    </tr>
    <tr>
        <td rowspan="3"><p>-</p></td>
        <td colspan="4"><p>prompt_tokens</p></td>
        <td><p>int</p></td>
        <td><p>用户输入的prompt文本对应的token长度。</p></td>
    </tr>
    <tr>
        <td colspan="4"><p>completion_tokens</p></td>
        <td><p>int</p></td>
        <td>
            <p>推理结果token数量。PD场景下统计P和D推理结果的总token数量。当一个请求的推理长度上限取maxIterTimes的值时，D节点响应中completion_tokens数量为maxIterTimes+1，即增加了P推理结果的首token数量。</p>
        </td>
    </tr>
    <tr>
        <td colspan="4"><p>total_tokens</p></td>
        <td><p>int</p></td>
        <td><p>请求和推理的总token数。</p></td>
    </tr>
    <tr>
        <td colspan="5"><p>prefill_time</p></td>
        <td><p>float</p></td>
        <td><p>推理首token时延。</p></td>
    </tr>
    <tr>
        <td colspan="5"><p>decode_time_arr</p></td>
        <td><p>list</p></td>
        <td><p>推理Decode时延数组。</p></td>
    </tr>
    </tbody>
</table>

### 表2 流式推理结果说明
<table cellpadding="4" cellspacing="0" frame="border" border="1" rules="all" data-header="6">
    <thead align="left">
    <tr>
        <th align="left" colspan="4" valign="top"><p>参数名</p></th>
        <th align="left" valign="top"><p>类型</p></th>
        <th align="left" valign="top"><p>说明</p></th>
    </tr>
    </thead>
    <tbody>
    <tr>
        <td colspan="4" valign="top"><p>data</p></td>
        <td valign="top"><p>object</p></td>
        <td valign="top"><p>一次推理返回的结果。</p></td>
    </tr>
    <tr>
        <td rowspan="15" valign="top"><p>-</p></td>
        <td colspan="3" valign="top"><p>id</p></td>
        <td valign="top"><p>string</p></td>
        <td valign="top"><p>请求ID。</p></td>
    </tr>
    <tr>
        <td colspan="3" valign="top"><p>object</p></td>
        <td valign="top"><p>string</p></td>
        <td valign="top"><p>目前都返回"chat.completion.chunk"。</p></td>
    </tr>
    <tr>
        <td colspan="3" valign="top"><p>created</p></td>
        <td valign="top"><p>integer</p></td>
        <td valign="top"><p>推理请求时间戳，精确到秒。</p></td>
    </tr>
    <tr>
        <td colspan="3" valign="top"><p>model</p></td>
        <td valign="top"><p>string</p></td>
        <td valign="top"><p>使用的推理模型。</p></td>
    </tr>
    <tr>
        <td colspan="3" valign="top"><p>full_text</p></td>
        <td valign="top"><p>string</p></td>
        <td valign="top">
            <p>全量文本结果，配置项<span>“fullTextEnabled”</span>=true时才有此返回值。</p>
            </td>
    </tr>
    <tr>
        <td colspan="3" valign="top"><p>usage</p></td>
        <td valign="top"><p>object</p></td>
        <td valign="top"><p>推理结果统计数据。</p></td>
    </tr>
    <tr>
        <td rowspan="3" valign="top"><p>-</p></td>
        <td colspan="2" valign="top"><p>prompt_tokens</p></td>
        <td valign="top"><p>int</p></td>
        <td valign="top"><p>用户输入的prompt文本对应的token长度。</p></td>
    </tr>
    <tr>
        <td colspan="2" valign="top"><p>completion_tokens</p></td>
        <td valign="top"><p>int</p></td>
        <td valign="top">
            <p>推理结果token数量。PD场景下统计P和D推理结果的总token数量。当一个请求的推理长度上限取maxIterTimes的值时，D节点响应中completion_tokens数量为maxIterTimes+1，即增加了P推理结果的首token数量。</p>
        </td>
    </tr>
    <tr>
        <td colspan="2" valign="top"><p>total_tokens</p></td>
        <td valign="top"><p>int</p></td>
        <td valign="top"><p>请求和推理的总token数。</p></td>
    </tr>
    <tr>
        <td colspan="3" valign="top"><p>choices</p></td>
        <td valign="top"><p>list</p></td>
        <td valign="top"><p>流式推理结果。</p></td>
    </tr>
    <tr>
        <td rowspan="5" valign="top"><p>-</p></td>
        <td colspan="2" valign="top"><p>index</p></td>
        <td valign="top"><p>integer</p></td>
        <td valign="top"><p>choices消息index，当前只能为0。</p></td>
    </tr>
    <tr>
        <td colspan="2" valign="top"><p>delta</p></td>
        <td valign="top"><p>object</p></td>
        <td valign="top"><p>推理返回结果，最后一个响应为空。</p></td>
    </tr>
    <tr>
        <td rowspan="2" valign="top"><p>-</p></td>
        <td valign="top"><p>role</p></td>
        <td valign="top"><p>string</p></td>
        <td valign="top"><p>角色，目前都返回"assistant"。</p></td>
    </tr>
    <tr>
        <td valign="top"><p>content</p></td>
        <td valign="top"><p>string</p></td>
        <td valign="top"><p>推理文本结果。</p></td>
    </tr>
    <tr>
        <td colspan="2" valign="top"><p>finish_reason</p></td>
        <td valign="top"><p>string</p></td>
        <td valign="top">
            <p>结束原因，只在最后一次推理结果返回。</p>
            <ul>
                <li>
                    stop：
                    <ul>
                        <li>请求被CANCEL或STOP，用户不感知，丢弃响应。</li>
                        <li>请求执行中出错，响应输出为空，err_msg非空。</li>
                        <li>请求输入校验异常，响应输出为空，err_msg非空。</li>
                        <li>请求遇eos结束符正常结束。</li>
                    </ul>
                </li>
                <li>
                    length：
                    <ul>
                        <li>请求因达到最大序列长度而结束，响应为最后一轮迭代输出。</li>
                        <li>请求因达到最大输出长度（包括请求和模型粒度）而结束，响应为最后一轮迭代输出。</li>
                    </ul>
                </li>
            </ul>
        </td>
    </tr>
    </tbody>
</table>


## 错误状态码说明
以下异常由http的response返回，模型异常在流中捕获处理

例：

```json
{
  "code": 701,
  "result": null,
  "message": 'Insufficient balance'
}
```

| code | 说明                     |
|------|------------------------|
| 701  | 余额不足                   |
| 702  | 未传Authorization        |
| 801  | apikey错误               |
| 802  | 请求超时                   |
| 9999 | 模型响应异常，根据message提示进行处理 |
